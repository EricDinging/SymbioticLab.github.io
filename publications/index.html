<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#fe6600">
<meta name="generator" content="Hexo 5.0.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png">
  <link rel="mask-icon" href="/assets/favicon/safari-pinned-tab.svg" color="#fe6600">
  <link rel="manifest" href="/assets/favicon/site.webmanifest">
  <meta name="msapplication-config" content="/assets/favicon/browserconfig.xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"symbioticlab.github.io","root":"/","scheme":"Mist","version":"8.0.0-rc.5","exturl":false,"sidebar":{"position":"right","display":"remove","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false};
  </script>

  <meta name="description" content="Work in progress                Filters:                                       All Venues                                      MLSys">
<meta property="og:type" content="website">
<meta property="og:title" content="Publications">
<meta property="og:url" content="https://symbioticlab.github.io/publications/index.html">
<meta property="og:site_name" content="SymbioticLab">
<meta property="og:description" content="Work in progress                Filters:                                       All Venues                                      MLSys">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-07-23T03:10:02.000Z">
<meta property="article:modified_time" content="2020-07-23T03:10:02.000Z">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://symbioticlab.github.io/publications/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'en'
  };
</script>

<link href="https://unpkg.com/@primer/css/dist/tooltips.css" rel="stylesheet" />
<link rel="stylesheet" href="/assets/publist/publist.css">


  <title>Publications | SymbioticLab
</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <main class="main">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">SymbioticLab</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-projects">

    <a href="/projects" rel="section"><i class="fa fa-code fa-fw"></i>Projects</a>

  </li>
        <li class="menu-item menu-item-publications">

    <a href="/publications" rel="section"><i class="fa fa-book fa-fw"></i>Publications</a>

  </li>
        <li class="menu-item menu-item-people">

    <a href="/people" rel="section"><i class="fa fa-user fa-fw"></i>People</a>

  </li>
        <li class="menu-item menu-item-funding">

    <a href="/funding" rel="section"><i class="fa fa-info fa-fw"></i>Funding</a>

  </li>
  </ul>
</nav>




</div>
      </header>

      
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div id="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


      <div class="main-inner">
        
  
  

        <div class="content page posts-expand">
          

    
    
    
    <div class="post-block" lang="en">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">Publications
</h1>

<div class="post-meta">
  

</div>

</header>

      
      
      
      <div class="post-body">
          <div class="note warning"><p>Work in progress</p>
</div>
<div class="publist">
    <div class="timeline-search-panel">
        <h4>Filters:</h4>
        <label class="select-box">
            <select>
                <option value="all" selected>All Venues</option>
                <optgroup label="Conferences">
                    <option value="MLSys">MLSys</option>
                </optgroup>
            </select>
            <span class="select-arrow">
                <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
                     version="1.1" viewBox="0 0 129 129"
                     enable-background="new 0 0 129 129"
                     width="512px" height="512px">
                    <g>
                        <path d="m121.3,34.6c-1.6-1.6-4.2-1.6-5.8,0l-51,51.1-51.1-51.1c-1.6-1.6-4.2-1.6-5.8,0-1.6,1.6-1.6,4.2 0,5.8l53.9,53.9c0.8,0.8 1.8,1.2 2.9,1.2 1,0 2.1-0.4 2.9-1.2l53.9-53.9c1.7-1.6 1.7-4.2 0.1-5.8z"/>
                    </g>
                </svg>
            </span>
        </label>
        <label class="check-box">
            <input type="checkbox" checked="checked" value="Conferences"> Conferences
        </label>
    </div> <!-- timeline-search-panel -->
    <div class="pub-list">
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2020"></span>
            </div>
            <ul>
                <li data-pub-venue="MLSys"
                    data-pub-cat="Conferences">
                    <div class="pub-block">
                        <div class="pub-title">
                            <a target="_blank" href="/publications/files/salus:mlsys20/salus-mlsys20.pdf">Fine-grained GPU sharing primitives for deep learning applications</a>
                            
                        </div>
                        <div class="pub-badges">
                            <span class="label default pub-badge">Artifacts Available</span>
                            <span class="label default pub-badge">Artifacts Evaluated Functional</span>
                            <span class="label default pub-badge">Artifacts Replicated</span>
                        </div>
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Peifeng-Yu ">Peifeng&nbspYu</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        <div class="pub-conference">
                            The 3rd Conference on Machine Learning and Systems
                            (<a target="_blank" title="19.2%"
                                href="https://mlsys.org/Conferences/2020">MLSys'20</a>)
                            <span class="pub-conference-acceptance">(Acceptance Rate: 19.2%)</span>
                        </div>
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote><p>Unlike traditional resources such as CPU or the network, modern GPUs do not natively support
fine-grained sharing primitives.
Consequently, implementing common policies such as time sharing and preemption are expensive. Worse,
when a deep learning (DL) application cannot completely use a GPU’s resources, the GPU cannot be efficiently shared
between multiple applications, leading to GPU underutilization.</p>
<p>We present Salus to enable two GPU sharing primitives: <strong>fast job
switching</strong> and <strong>memory sharing</strong>, to achieve fine-grained GPU sharing
among multiple DL applications. Salus is an efficient, consolidated
execution service that exposes the GPU to different DL applications, and it
enforces fine-grained sharing by performing iteration scheduling and
addressing associated memory management issues. We show that these primitives
can then be used to implement flexible sharing policies. Our integration of
Salus with TensorFlow and evaluation on popular DL jobs shows that Salus
can improve the average completion time of DL training jobs by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.19</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">3.19\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord">.</span><span class="mord">1</span><span class="mord">9</span><span class="mord">×</span></span></span></span>, GPU utilization for
hyper-parameter tuning by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2.38</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">2.38\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord">.</span><span class="mord">3</span><span class="mord">8</span><span class="mord">×</span></span></span></span>, and GPU utilization of DL inference applications by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>42</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">42\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mord">2</span><span class="mord">×</span></span></span></span> over not sharing
the GPU and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">6\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">6</span><span class="mord">×</span></span></span></span> over NVIDIA MPS with small overhead.</p>

                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a target="_blank" href="/publications/files/salus:mlsys20/salus-mlsys20.pdf">[paper]</a>
                            <a target="_blank" href="/publications/files/salus:mlsys20/salus-mlsys20-talk.pptx">[talk]</a>
                            <a target="_blank" href="/publications/files/salus:mlsys20/salus-mlsys20-poster.pdf">[poster]</a>
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{salus:mlsys20,
    author    = {Peifeng Yu and Mosharaf Chowdhury},
    booktitle = {MLSys},
    title     = {Fine-Grained {GPU} Sharing Primitives for Deep Learning Applications},
    year      = {2020},
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            AlloX: compute allocation in hybrid clusters
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Tan-N. Le ">Tan&nbspN.&nbspLe</span>, 
                            <span class="pub-author pub-author-Xiao-Sun ">Xiao&nbspSun</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Zhenhua-Liu ">Zhenhua&nbspLiu</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{allox:eurosys20,
    author    = {Tan N. Le and Xiao Sun and Mosharaf Chowdhury and Zhenhua Liu},
    booktitle = {ACM EuroSys},
    title     = {AlloX: compute allocation in hybrid clusters},
    year      = {2020},
    pages     = {31:1--31:16},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Sol: Fast distributed computation over slow networks
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, 
                            <span class="pub-author pub-author-Jie-You ">Jie&nbspYou</span>, 
                            <span class="pub-author pub-author-Xiangfeng-Zhu ">Xiangfeng&nbspZhu</span>, 
                            <span class="pub-author pub-author-Harsha-V. Madhyastha ">Harsha&nbspV.&nbspMadhyastha</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{sol:nsdi20,
    author    = {Fan Lai and Jie You and Xiangfeng Zhu and Harsha V. Madhyastha and Mosharaf Chowdhury},
    booktitle = {USENIX NSDI},
    title     = {Sol: Fast Distributed Computation Over Slow Networks},
    year      = {2020},
    pages     = {273--288},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Near-optimal latency versus cost tradeoffs in geo-distributed storage
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Muhammed-Uluyol ">Muhammed&nbspUluyol</span>, 
                            <span class="pub-author pub-author-Anthony-Huang ">Anthony&nbspHuang</span>, 
                            <span class="pub-author pub-author-Ayush-Goel ">Ayush&nbspGoel</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Harsha-V. Madhyastha ">Harsha&nbspV.&nbspMadhyastha</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{pando:nsdi20,
    author    = {Muhammed Uluyol and Anthony Huang and Ayush Goel and Mosharaf Chowdhury and Harsha V. Madhyastha},
    booktitle = {USENIX NSDI},
    title     = {Near-Optimal Latency Versus Cost Tradeoffs in Geo-Distributed Storage},
    year      = {2020},
    pages     = {157--180},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            NetLock: Fast, centralized lock management using programmable switches
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Zhuolong-Yu ">Zhuolong&nbspYu</span>, 
                            <span class="pub-author pub-author-Yiwen-Zhang ">Yiwen&nbspZhang</span>, 
                            <span class="pub-author pub-author-Vladimir-Braverman ">Vladimir&nbspBraverman</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Xin-Jin ">Xin&nbspJin</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{netlock:sigcomm20,
    author    = {Zhuolong Yu and Yiwen Zhang and Vladimir Braverman and Mosharaf Chowdhury and Xin Jin},
    booktitle = {ACM SIGCOMM},
    title     = {NetLock: Fast, Centralized Lock Management Using Programmable Switches},
    year      = {2020},
    pages     = {126--138},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Effectively prefetching remote memory with leap
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Hasan-Al Maruf ">Hasan&nbspAl&nbspMaruf</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{leap:atc20,
    author    = {Hasan Al Maruf and Mosharaf Chowdhury},
    booktitle = {USENIX ATC},
    title     = {Effectively Prefetching Remote Memory with Leap},
    year      = {2020},
    pages     = {843--857},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2019"></span>
            </div>
            <ul>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Tiresias: A GPU cluster manager for distributed deep learning
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Juncheng-Gu ">Juncheng&nbspGu</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Kang-G. Shin ">Kang&nbspG.&nbspShin</span>, 
                            <span class="pub-author pub-author-Yibo-Zhu ">Yibo&nbspZhu</span>, 
                            <span class="pub-author pub-author-Myeongjae-Jeon ">Myeongjae&nbspJeon</span>, 
                            <span class="pub-author pub-author-Junjie-Qian ">Junjie&nbspQian</span>, 
                            <span class="pub-author pub-author-Hongqiang-Harry Liu ">Hongqiang&nbspHarry&nbspLiu</span>, and 
                            <span class="pub-author pub-author-Chuanxiong-Guo ">Chuanxiong&nbspGuo</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{tiresias:nsdi19,
    author    = {Juncheng Gu and Mosharaf Chowdhury and Kang G. Shin and Yibo Zhu and Myeongjae Jeon and Junjie Qian and Hongqiang Harry Liu and Chuanxiong Guo},
    booktitle = {USENIX NSDI},
    title     = {Tiresias: {A} {GPU} Cluster Manager for Distributed Deep Learning},
    year      = {2019},
    pages     = {485--500},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Near optimal coflow scheduling in networks
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Samir-Khuller ">Samir&nbspKhuller</span>, 
                            <span class="pub-author pub-author-Manish-Purohit ">Manish&nbspPurohit</span>, 
                            <span class="pub-author pub-author-Sheng-Yang ">Sheng&nbspYang</span>, and 
                            <span class="pub-author pub-author-Jie-You ">Jie&nbspYou</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{nocs:spaa19,
    author    = {Mosharaf Chowdhury and Samir Khuller and Manish Purohit and Sheng Yang and Jie You},
    booktitle = {ACM SPAA},
    title     = {Near Optimal Coflow Scheduling in Networks},
    year      = {2019},
    pages     = {123--134},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Salus: Fine-grained GPU sharing primitives for deep learning applications
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Peifeng-Yu ">Peifeng&nbspYu</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@article{salus:arxiv19,
    author        = {Peifeng Yu and Mosharaf Chowdhury},
    journal       = {CoRR},
    title         = {Salus: Fine-Grained {GPU} Sharing Primitives for Deep Learning Applications},
    year          = {2019},
    volume        = {abs/1902.04610},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1902-04610.bib},
    eprint        = {1902.04610},
    url           = {http://arxiv.org/abs/1902.04610},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Terra: Scalable cross-layer GDA optimizations
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Jie-You ">Jie&nbspYou</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@article{terra:arxiv19,
    author        = {Jie You and Mosharaf Chowdhury},
    journal       = {CoRR},
    title         = {Terra: Scalable Cross-Layer {GDA} Optimizations},
    year          = {2019},
    volume        = {abs/1904.08480},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1904-08480.bib},
    eprint        = {1904.08480},
    url           = {http://arxiv.org/abs/1904.08480},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            RDMA performance isolation with justitia
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Yiwen-Zhang ">Yiwen&nbspZhang</span>, 
                            <span class="pub-author pub-author-Yue-Tan ">Yue&nbspTan</span>, 
                            <span class="pub-author pub-author-Brent-Stephens ">Brent&nbspStephens</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@article{justitia:arxiv19,
    author        = {Yiwen Zhang and Yue Tan and Brent Stephens and Mosharaf Chowdhury},
    journal       = {CoRR},
    title         = {{RDMA} Performance Isolation With Justitia},
    year          = {2019},
    volume        = {abs/1905.04437},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1905-04437.bib},
    eprint        = {1905.04437},
    url           = {http://arxiv.org/abs/1905.04437},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Near optimal coflow scheduling in networks
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Samir-Khuller ">Samir&nbspKhuller</span>, 
                            <span class="pub-author pub-author-Manish-Purohit ">Manish&nbspPurohit</span>, 
                            <span class="pub-author pub-author-Sheng-Yang ">Sheng&nbspYang</span>, and 
                            <span class="pub-author pub-author-Jie-You ">Jie&nbspYou</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@article{nocs:arxiv19,
    author        = {Mosharaf Chowdhury and Samir Khuller and Manish Purohit and Sheng Yang and Jie You},
    journal       = {CoRR},
    title         = {Near Optimal Coflow Scheduling in Networks},
    year          = {2019},
    volume        = {abs/1906.06851},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1906-06851.bib},
    eprint        = {1906.06851},
    url           = {http://arxiv.org/abs/1906.06851},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Mitigating the performance-efficiency tradeoff in resilient memory disaggregation
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Youngmoon-Lee ">Youngmoon&nbspLee</span>, 
                            <span class="pub-author pub-author-Hassan-Al Maruf ">Hassan&nbspAl&nbspMaruf</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Kang-G. Shin ">Kang&nbspG.&nbspShin</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@article{hydra:arxiv19,
    author        = {Youngmoon Lee and Hassan Al Maruf and Mosharaf Chowdhury and Kang G. Shin},
    journal       = {CoRR},
    title         = {Mitigating the Performance-Efficiency Tradeoff in Resilient Memory Disaggregation},
    year          = {2019},
    volume        = {abs/1910.09727},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1910-09727.bib},
    eprint        = {1910.09727},
    url           = {http://arxiv.org/abs/1910.09727},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Effectively prefetching remote memory with leap
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Hasan-Al Maruf ">Hasan&nbspAl&nbspMaruf</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@article{leap:arxiv19,
    author        = {Hasan Al Maruf and Mosharaf Chowdhury},
    journal       = {CoRR},
    title         = {Effectively Prefetching Remote Memory with Leap},
    year          = {2019},
    volume        = {abs/1911.09829},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1911-09829.bib},
    eprint        = {1911.09829},
    url           = {http://arxiv.org/abs/1911.09829},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            BoPF: Mitigating the burstiness-fairness tradeoff in multi-resource clusters
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Tan-N. Le ">Tan&nbspN.&nbspLe</span>, 
                            <span class="pub-author pub-author-Xiao-Sun ">Xiao&nbspSun</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Zhenhua-Liu ">Zhenhua&nbspLiu</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@article{bopf:arxiv19,
    author        = {Tan N. Le and Xiao Sun and Mosharaf Chowdhury and Zhenhua Liu},
    journal       = {CoRR},
    title         = {BoPF: Mitigating the Burstiness-Fairness Tradeoff in Multi-Resource Clusters},
    year          = {2019},
    volume        = {abs/1912.03523},
    archiveprefix = {arXiv},
    bibsource     = {dblp computer science bibliography, https://dblp.org},
    biburl        = {https://dblp.org/rec/journals/corr/abs-1912-03523.bib},
    eprint        = {1912.03523},
    url           = {http://arxiv.org/abs/1912.03523},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2018"></span>
            </div>
            <ul>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Pas de deux: Shape the Circuits, and Shape the Apps too!
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Hong-Zhang ">Hong&nbspZhang</span>, 
                            <span class="pub-author pub-author-Kai-Chen ">Kai&nbspChen</span>, and 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{pdd:apnet18,
    author    = {Hong Zhang and Kai Chen and Mosharaf Chowdhury},
    booktitle = {ACM APNet},
    title     = {Pas de deux: Shape the Circuits, and Shape the Apps too!},
    year      = {2018},
    pages     = {29--35},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Bridging the GAP: Towards approximate graph analytics
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Anand-Padmanabha Iyer ">Anand&nbspPadmanabha&nbspIyer</span>, 
                            <span class="pub-author pub-author-Aurojit-Panda ">Aurojit&nbspPanda</span>, 
                            <span class="pub-author pub-author-Shivaram-Venkataraman ">Shivaram&nbspVenkataraman</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Aditya-Akella ">Aditya&nbspAkella</span>, 
                            <span class="pub-author pub-author-Scott-Shenker ">Scott&nbspShenker</span>, and 
                            <span class="pub-author pub-author-Ion-Stoica ">Ion&nbspStoica</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{aga:grades-nda18,
    author    = {Anand Padmanabha Iyer and Aurojit Panda and Shivaram Venkataraman and Mosharaf Chowdhury and Aditya Akella and Scott Shenker and Ion Stoica},
    booktitle = {ACM SIGMOD GRADES-NDA},
    title     = {Bridging the {GAP}: Towards Approximate Graph analytics},
    year      = {2018},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Monarch: Gaining command on geo-distributed graph analytics
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Anand-Padmanabha Iyer ">Anand&nbspPadmanabha&nbspIyer</span>, 
                            <span class="pub-author pub-author-Aurojit-Panda ">Aurojit&nbspPanda</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Aditya-Akella ">Aditya&nbspAkella</span>, 
                            <span class="pub-author pub-author-Scott-Shenker ">Scott&nbspShenker</span>, and 
                            <span class="pub-author pub-author-Ion-Stoica ">Ion&nbspStoica</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{monarch:hotcloud18,
    author    = {Anand Padmanabha Iyer and Aurojit Panda and Mosharaf Chowdhury and Aditya Akella and Scott Shenker and Ion Stoica},
    booktitle = {USENIX HotCloud},
    title     = {Monarch: Gaining Command on Geo-Distributed Graph Analytics},
    year      = {2018},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            To relay or not to relay for inter-cloud transfers?
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Fan-Lai ">Fan&nbspLai</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Harsha-V. Madhyastha ">Harsha&nbspV.&nbspMadhyastha</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{relay:hotcloud18,
    author    = {Fan Lai and Mosharaf Chowdhury and Harsha V. Madhyastha},
    booktitle = {USENIX HotCloud},
    title     = {To Relay or Not to Relay for Inter-Cloud Transfers?},
    year      = {2018},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Mitigating the latency-accuracy trade-off in mobile data analytics systems
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Anand-Padmanabha Iyer ">Anand&nbspPadmanabha&nbspIyer</span>, 
                            <span class="pub-author pub-author-Li-Erran Li ">Li&nbspErran&nbspLi</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Ion-Stoica ">Ion&nbspStoica</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{cellscope:mobicom18,
    author    = {Anand Padmanabha Iyer and Li Erran Li and Mosharaf Chowdhury and Ion Stoica},
    booktitle = {ACM MobiCom},
    title     = {Mitigating the Latency-Accuracy Trade-off in Mobile Data Analytics Systems},
    year      = {2018},
    pages     = {513--528},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Dynamic query re-planning using QOOP
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Kshiteej-Mahajan ">Kshiteej&nbspMahajan</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Aditya-Akella ">Aditya&nbspAkella</span>, and 
                            <span class="pub-author pub-author-Shuchi-Chawla ">Shuchi&nbspChawla</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{qoop:osdi18,
    author    = {Kshiteej Mahajan and Mosharaf Chowdhury and Aditya Akella and Shuchi Chawla},
    booktitle = {USENIX OSDI},
    title     = {Dynamic Query Re-Planning using {QOOP}},
    year      = {2018},
    pages     = {253--267},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Distributed lock management with RDMA: Decentralization without starvation
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Dong-Young Yoon ">Dong&nbspYoung&nbspYoon</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Barzan-Mozafari ">Barzan&nbspMozafari</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{dslr:sigmod18,
    author    = {Dong Young Yoon and Mosharaf Chowdhury and Barzan Mozafari},
    booktitle = {ACM SIGMOD},
    title     = {Distributed Lock Management with {RDMA}: Decentralization without Starvation},
    year      = {2018},
    pages     = {1571--1586},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Fair allocation of heterogeneous and interchangeable resources
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Xiao-Sun ">Xiao&nbspSun</span>, 
                            <span class="pub-author pub-author-Tan-N. Le ">Tan&nbspN.&nbspLe</span>, 
                            <span class="pub-author pub-author-Mosharaf-Chowdhury ">Mosharaf&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Zhenhua-Liu ">Zhenhua&nbspLiu</span>
                        </div>
                        
                        
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{allox:mama18,
    author    = {Xiao Sun and Tan N. Le and Mosharaf Chowdhury and Zhenhua Liu},
    booktitle = {ACM SIGMETRICS MAMA},
    title     = {Fair Allocation of Heterogeneous and Interchangeable Resources},
    year      = {2018},
}
">[bibtex]</a>
                            
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2017"></span>
            </div>
            <ul>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Decentralized memory disaggregation over low-latency networks
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-J.-Gu ">J.&nbspGu</span>, 
                            <span class="pub-author pub-author-Y.-Lee ">Y.&nbspLee</span>, 
                            <span class="pub-author pub-author-Y.-Zhang ">Y.&nbspZhang</span>, 
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-K.-G. Shin ">K.&nbspG.&nbspShin</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Memory disaggregation can expose remote memory across a cluster to local applications. However, existing proposals call for new architectures and/or new programming models, making them infeasible. We have developed a practical memory disaggregation solution, Infiniswap, which is a remote memory paging system for clusters with lowlatency, kernel-bypass networks such as RDMA. Infiniswap opportunistically harvests and transparently exposes unused memory across the cluster to unmodified applications by dividing the swap space of each machine into many chunks and distributing them to unused memory of many remote machines. For scalability, it leverages the power of many choices to perform decentralized memory chunk placements and evictions. Applications using Infiniswap receive large performance boosts when their working sets are larger than their physical memory allocations.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@article{infiniswap:login17,
    Title                    = {Decentralized Memory Disaggregation Over Low-Latency Networks},
    Author                   = {J. Gu and Y. Lee and Y. Zhang and M. Chowdhury and K. G. Shin},
    Journal                  = {USENIX ;login:},
    Year                     = {2017},
    Month                    = {December},
    Number                   = {4},
    Pages                    = {42--48},
    Volume                   = {42},
    Abstract                 = {Memory disaggregation can expose remote memory across a cluster to local applications. However, existing proposals call for new architectures and/or new programming models, making them infeasible. We have developed a practical memory disaggregation solution, Infiniswap, which is a remote memory paging system for clusters with lowlatency, kernel-bypass networks such as RDMA. Infiniswap opportunistically harvests and transparently exposes unused memory across the cluster to unmodified applications by dividing the swap space of each machine into many chunks and distributing them to unused memory of many remote machines. For scalability, it leverages the power of many choices to perform decentralized memory chunk placements and evictions. Applications using Infiniswap receive large performance boosts when their working sets are larger than their physical memory allocations.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Resilient datacenter load balancing in the wild
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-H.-Zhang ">H.&nbspZhang</span>, 
                            <span class="pub-author pub-author-J.-Zhang ">J.&nbspZhang</span>, 
                            <span class="pub-author pub-author-W.-Bai K. Chen ">W.&nbspBai&nbspK.&nbspChen</span>, and 
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Production datacenters operate under various uncertainties such as traffic dynamics, topology asymmetry, and failures. Therefore, datacenter load balancing schemes must be resilient to these uncertainties; i.e., they should accurately sense path conditions and timely react to mitigate the fallouts. Despite significant efforts, prior solutions have important drawbacks. On the one hand, solutions such as Presto and DRB are oblivious to path conditions and blindly reroute at fixed granularity. On the other hand, solutions such as CONGA and CLOVE can sense congestion, but they can only reroute when flowlets emerge; thus, they cannot always react timely to uncertainties. To make things worse, these solutions fail to detect/handle failures such as blackholes and random packet drops, which greatly degrades their performance. In this paper, we introduce Hermes, a datacenter load balancer that is resilient to the aforementioned uncertainties. At its heart, Hermes leverages comprehensive sensing to detect path conditions including failures unattended before, and it reacts using timely yet cautious rerouting. Hermes is a practical edge-based solution with no switch modification. We have implemented Hermes with commodity switches and evaluated it through both testbed experiments and large-scale simulations. Our results show that Hermes achieves comparable performance to CONGA and Presto in normal cases, and well handles uncertainties: under asymmetries, Hermes achieves up to 10% and 20% better flow completion time (FCT) than CONGA and CLOVE; under switch failures, it outperforms all other schemes by over 32%.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{hermes:sigcomm17,
    Title                    = {Resilient Datacenter Load Balancing in the Wild},
    Author                   = {H. Zhang and J. Zhang and W. Bai K. Chen and M. Chowdhury},
    Booktitle                = {ACM SIGCOMM},
    Year                     = {2017},
    Month                    = {August},
    Abstract                 = {Production datacenters operate under various uncertainties such as traffic dynamics, topology asymmetry, and failures. Therefore, datacenter load balancing schemes must be resilient to these uncertainties; i.e., they should accurately sense path conditions and timely react to mitigate the fallouts. Despite significant efforts, prior solutions have important drawbacks. On the one hand, solutions such as Presto and DRB are oblivious to path conditions and blindly reroute at fixed granularity. On the other hand, solutions such as CONGA and CLOVE can sense congestion, but they can only reroute when flowlets emerge; thus, they cannot always react timely to uncertainties. To make things worse, these solutions fail to detect/handle failures such as blackholes and random packet drops, which greatly degrades their performance.

In this paper, we introduce Hermes, a datacenter load balancer that is resilient to the aforementioned uncertainties. At its heart, Hermes leverages comprehensive sensing to detect path conditions including failures unattended before, and it reacts using timely yet cautious rerouting. Hermes is a practical edge-based solution with no switch modification. We have implemented Hermes with commodity switches and evaluated it through both testbed experiments and large-scale simulations. Our results show that Hermes achieves comparable performance to CONGA and Presto in normal cases, and well handles uncertainties: under asymmetries, Hermes achieves up to 10% and 20% better flow completion time (FCT) than CONGA and CLOVE; under switch failures, it outperforms all other schemes by over 32%.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Performance isolation anomalies in RDMA
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-Y.-Zhang ">Y.&nbspZhang</span>, 
                            <span class="pub-author pub-author-J.-Gu ">J.&nbspGu</span>, 
                            <span class="pub-author pub-author-Y.-Lee ">Y.&nbspLee</span>, 
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-K.-G. Shin ">K.&nbspG.&nbspShin</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>To meet the increasing throughput and latency demands of modern applications, many operators are rapidly deploying RDMA in their datacenters. At the same time, developers are re-designing their software to take advantage of RDMA's benefits for individual applications. However, when it comes to RDMA's performance, many simple questions remain open. In this paper, we consider the performance isolation characteristics of RDMA. Specifically, we conduct three sets of experiments – three combinations of one throughput-sensitive flow and one latency-sensitive flow – in a controlled environment, observe large discrepancies in RDMA performance with and without the presence of a competing flow, and describe our progress in identifying plausible root-causes.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{fairdma:kbnets2017,
    Title                    = {Performance Isolation Anomalies in {RDMA}},
    Author                   = {Y. Zhang and J. Gu and Y. Lee and M. Chowdhury and K. G. Shin},
    Booktitle                = {ACM SIGCOMMKBNets},
    Year                     = {2017},
    Month                    = {August},
    Abstract                 = {To meet the increasing throughput and latency demands of modern applications, many operators are rapidly deploying RDMA in their datacenters. At the same time, developers are re-designing their software to take advantage of RDMA's benefits for individual applications. However, when it comes to RDMA's performance, many simple questions remain open.

In this paper, we consider the performance isolation characteristics of RDMA. Specifically, we conduct three sets of experiments -- three combinations of one throughput-sensitive flow and one latency-sensitive flow -- in a controlled environment, observe large discrepancies in RDMA performance with and without the presence of a competing flow, and describe our progress in identifying plausible root-causes.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            No! Not another deep learning framework
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-L.-Nguyen ">L.&nbspNguyen</span>, 
                            <span class="pub-author pub-author-P.-Yu ">P.&nbspYu</span>, and 
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>In recent years, deep learning has pervaded many areas of computing due to the confluence of an explosive growth of large-scale computing capabilities, availability of datasets, and advances in learning techniques. While this rapid growth has resulted in diverse deep learning frameworks, it has also led to inefficiencies for both the users and developers of these frameworks. Specifically, adopting useful techniques across frameworks – both to perform learning tasks and to optimize performance – involves significant repetitions and reinventions. In this paper, we observe that despite their diverse origins, many of these frameworks share architectural similarities. We argue that by introducing a common representation of learning tasks and a hardware abstraction model to capture compute heterogeneity, we might be able to relieve machine learning researchers from dealing with low-level systems issues and systems researchers from being tied to any specific framework. We expect this decoupling to accelerate progress in both domains.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{deepstack:hotos17,
    Title                    = {No! Not Another Deep Learning Framework},
    Author                   = {L. Nguyen and P. Yu and M. Chowdhury},
    Booktitle                = {ACM HotOS},
    Year                     = {2017},
    Month                    = {May},
    Abstract                 = {In recent years, deep learning has pervaded many areas of computing due to the confluence of an explosive growth of large-scale computing capabilities, availability of datasets, and advances in learning techniques. While this rapid growth has resulted in diverse deep learning frameworks, it has also led to inefficiencies for both the users and developers of these frameworks. Specifically, adopting useful techniques across frameworks -- both to perform learning tasks and to optimize performance -- involves significant repetitions and reinventions.

In this paper, we observe that despite their diverse origins, many of these frameworks share architectural similarities. We argue that by introducing a common representation of learning tasks and a hardware abstraction model to capture compute heterogeneity, we might be able to relieve machine learning researchers from dealing with low-level systems issues and systems researchers from being tied to any specific framework. We expect this decoupling to accelerate progress in both domains.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Efficient memory disaggregation with Infiniswap
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-J.-Gu ">J.&nbspGu</span>, 
                            <span class="pub-author pub-author-Y.-Lee ">Y.&nbspLee</span>, 
                            <span class="pub-author pub-author-Y.-Zhang ">Y.&nbspZhang</span>, 
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-K.-G. Shin ">K.&nbspG.&nbspShin</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Memory-intensive applications suffer large performance loss when their working sets do not fully fit in memory. Yet, they cannot leverage otherwise unused remote memory when paging out to disks even in the presence of large imbalance in memory utilizations across a cluster. Existing proposals for memory disaggregation call for new architectures, new hardware designs, and/or new programming models, making them infeasible. This paper describes the design and implementation of Infiniswap, a remote memory paging system designed specifically for an RDMA network. Infiniswap opportunistically harvests and transparently exposes unused memory to unmodified applications by dividing the swap space of each machine into many slabs and distributing them across many machines' remote memory. Because one-sided RDMA operations bypass remote CPUs, Infiniswap leverages the power of many choices to perform decentralized slab placements and evictions. We have implemented and deployed Infiniswap on an RDMA cluster without any modifications to user applications or the OS and evaluated its effectiveness using multiple workloads running on unmodified VoltDB, Memcached, PowerGraph, GraphX, and Apache Spark. Using Infiniswap, throughputs of these applications improve between 4X (0.94X) to 15.4X (7.8X) over disk (Mellanox nbdX), and median and tail latencies between 5.4X (2X) and 61X (2.3X). Infiniswap achieves these with negligible remote CPU usage, whereas nbdX becomes CPU-bound. Infiniswap increases the overall memory utilization of a cluster and works well at scale.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{infiniswap:nsdi17,
    Title                    = {Efficient Memory Disaggregation with {Infiniswap}},
    Author                   = {J. Gu and Y. Lee and Y. Zhang and M. Chowdhury and K. G. Shin},
    Booktitle                = {USENIX NSDI},
    Year                     = {2017},
    Month                    = {March},
    Abstract                 = {Memory-intensive applications suffer large performance loss when their working sets do not fully fit in memory. Yet, they cannot leverage otherwise unused remote memory when paging out to disks even in the presence of large imbalance in memory utilizations across a cluster. Existing proposals for memory disaggregation call for new architectures, new hardware designs, and/or new programming models, making them infeasible.

This paper describes the design and implementation of Infiniswap, a remote memory paging system designed specifically for an RDMA network. Infiniswap opportunistically harvests and transparently exposes unused memory to unmodified applications by dividing the swap space of each machine into many slabs and distributing them across many machines' remote memory. Because one-sided RDMA operations bypass remote CPUs, Infiniswap leverages the power of many choices to perform decentralized slab placements and evictions.

We have implemented and deployed Infiniswap on an RDMA cluster without any modifications to user applications or the OS and evaluated its effectiveness using multiple workloads running on unmodified VoltDB, Memcached, PowerGraph, GraphX, and Apache Spark. Using Infiniswap, throughputs of these applications improve between 4X (0.94X) to 15.4X (7.8X) over disk (Mellanox nbdX), and median and tail latencies between 5.4X (2X) and 61X (2.3X). Infiniswap achieves these with negligible remote CPU usage, whereas nbdX becomes CPU-bound. Infiniswap increases the overall memory utilization of a cluster and works well at scale.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
        <section class="year">
            <div class="year-mark-wrapper">
                <span class="year-mark" data-year="2016"></span>
            </div>
            <ul>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Altruistic scheduling in multi-resource clusters
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-R.-Grandl ">R.&nbspGrandl</span>, 
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-A.-Akella ">A.&nbspAkella</span>, and 
                            <span class="pub-author pub-author-G.-Ananthanarayanan ">G.&nbspAnanthanarayanan</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Given the well-known tradeoffs between fairness, performance, and efficiency, modern cluster schedulers often prefer instantaneous fairness as their primary objective to ensure performance isolation between users and groups. However, instantaneous, short-term convergence to fairness often does not result in noticeable long-term benefits. Instead, we propose an altruistic, long-term approach, Carbyne, where jobs yield fractions of their allocated resources without impacting their own completion times. We show that leftover resources collected via altruisms of many jobs can then be rescheduled to further secondary goals such as application-level performance and cluster efficiency without impacting performance isolation. Deployments and large-scale simulations show that Carbyne closely approximates the state-of-the-art solutions (e.g., DRF [27]) in terms of performance isolation, while providing 1.26X better efficiency and 1.59X lower average job completion time.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{carbyne:osdi16,
    Title                    = {Altruistic Scheduling in Multi-Resource Clusters},
    Author                   = {R. Grandl and M. Chowdhury and A. Akella and G. Ananthanarayanan},
    Booktitle                = {USENIX OSDI},
    Year                     = {2016},
    Month                    = {October},
    Abstract                 = {Given the well-known tradeoffs between fairness, performance, and efficiency, modern cluster schedulers often prefer instantaneous fairness as their primary objective to ensure performance isolation between users and groups. However, instantaneous, short-term convergence to fairness often does not result in noticeable long-term benefits. Instead, we propose an altruistic, long-term approach, Carbyne, where jobs yield fractions of their allocated resources without impacting their own completion times. We show that leftover resources collected via altruisms of many jobs can then be rescheduled to further secondary goals such as application-level performance and cluster efficiency without impacting performance isolation. Deployments and large-scale simulations show that Carbyne closely approximates the state-of-the-art solutions (e.g., DRF [27]) in terms of performance isolation, while providing 1.26X better efficiency and 1.59X lower average job completion time.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            EC-Cache: Load-balanced, low-latency cluster caching with online erasure coding
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-K.-V. Rashmi ">K.&nbspV.&nbspRashmi</span>, 
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-J.-Kosaian ">J.&nbspKosaian</span>, 
                            <span class="pub-author pub-author-I.-Stoica ">I.&nbspStoica</span>, and 
                            <span class="pub-author pub-author-K.-Ramchandran ">K.&nbspRamchandran</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Data-intensive clusters and object stores are increasingly relying on in-memory object caching to meet the I/O performance demands. These systems routinely face the challenges of popularity skew, background load imbalance, and server failures, which result in severe load imbalance across storage servers and degraded I/O performance. Selective replication is a commonly used technique to tackle these challenges, where the number of cached replicas of an object is proportional to its popularity. In this paper, we explore an alternative approach using erasure coding. EC-Cache is a load-balanced, low latency cluster cache that uses online erasure coding to overcome the limitations of selective replication. EC-Cache employs erasure coding by: (i) splitting and erasure coding individual objects during writes, and (ii) late binding, wherein obtaining any k out of (k + r) splits of an object are sufficient, during reads. As compared to selective replication, EC-Cache improves load balancing by more than 3X and reduces the median and tail read latencies by more than 2X, while using the same amount of memory. EC-Cache does so using 10% additional bandwidth and a small increase in the amount of stored metadata. The benefits offered by EC-Cache are further amplified in the presence of background network load imbalance and server failures.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{eccache:osdi16,
    Title                    = {{EC-Cache}: Load-Balanced, Low-Latency Cluster Caching with Online Erasure Coding},
    Author                   = {K. V. Rashmi and M. Chowdhury and J. Kosaian and I. Stoica and K. Ramchandran},
    Booktitle                = {USENIX OSDI},
    Year                     = {2016},
    Month                    = {October},
    Abstract                 = {Data-intensive clusters and object stores are increasingly relying on in-memory object caching to meet the I/O performance demands. These systems routinely face the challenges of popularity skew, background load imbalance, and server failures, which result in severe load imbalance across storage servers and degraded I/O performance. Selective replication is a commonly used technique to tackle these challenges, where the number of cached replicas of an object is proportional to its popularity. In this paper, we explore an alternative approach using erasure coding.

EC-Cache is a load-balanced, low latency cluster cache that uses online erasure coding to overcome the limitations of selective replication. EC-Cache employs erasure coding by: (i) splitting and erasure coding individual objects during writes, and (ii) late binding, wherein obtaining any k out of (k + r) splits of an object are sufficient, during reads. As compared to selective replication, EC-Cache improves load balancing by more than 3X and reduces the median and tail read latencies by more than 2X, while using the same amount of memory. EC-Cache does so using 10% additional bandwidth and a small increase in the amount of stored metadata. The benefits offered by EC-Cache are further amplified in the presence of background network load imbalance and server failures.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            CODA: Toward automatically identifying and scheduling COflows in the DArk
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-H.-Zhang ">H.&nbspZhang</span>, 
                            <span class="pub-author pub-author-L.-Chen ">L.&nbspChen</span>, 
                            <span class="pub-author pub-author-B.-Yi ">B.&nbspYi</span>, 
                            <span class="pub-author pub-author-K.-Chen ">K.&nbspChen</span>, 
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-Y.-Geng ">Y.&nbspGeng</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>Leveraging application-level requirements using coflows has recently been shown to improve application-level communication performance in data-parallel clusters. However, existing coflow-based solutions rely on modifying applications to extract coflows, making them inapplicable to many practical scenarios. In this paper, we present CODA, a first attempt at automatically identifying and scheduling coflows without any application modifications. We employ an incremental clustering algorithm to perform fast, application-transparent coflow identification and complement it by proposing an error-tolerant coflow scheduler to mitigate occasional identification errors. Testbed experiments and large-scale simulations with production workloads show that CODA can identify coflows with over 90% accuracy, and its scheduler is robust to inaccuracies, enabling communication stages to complete 2.4X (5.1X) faster on average (95th percentile) compared to per-flow mechanisms. Overall, CODA�s performance is comparable to that of solutions requiring application modifications.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{coda:sigcomm16,
    Title                    = {{CODA}: Toward Automatically Identifying and Scheduling {CO}flows in the {DA}rk},
    Author                   = {H. Zhang and L. Chen and B. Yi and K. Chen and M. Chowdhury and Y. Geng},
    Booktitle                = {ACM SIGCOMM},
    Year                     = {2016},
    Month                    = {August},
    Abstract                 = {Leveraging application-level requirements using coflows has recently been shown to improve application-level communication performance in data-parallel clusters. However, existing coflow-based solutions rely on modifying applications to extract coflows, making them inapplicable to many practical scenarios.

In this paper, we present CODA, a first attempt at automatically identifying and scheduling coflows without any application modifications. We employ an incremental clustering algorithm to perform fast, application-transparent coflow identification and complement it by proposing an error-tolerant coflow scheduler to mitigate occasional identification errors. Testbed experiments and large-scale simulations with production workloads show that CODA can identify coflows with over 90% accuracy, and its scheduler is robust to inaccuracies, enabling communication stages to complete 2.4X (5.1X) faster on average (95th percentile) compared to per-flow mechanisms. Overall, CODA�s performance is comparable to that of solutions requiring application modifications.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            Fast and accurate performance analysis of LTE radio access networks
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-A.-P. Iyer ">A.&nbspP.&nbspIyer</span>, 
                            <span class="pub-author pub-author-I.-Stoica ">I.&nbspStoica</span>, 
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>, and 
                            <span class="pub-author pub-author-L.-E. Li ">L.&nbspE.&nbspLi</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>An increasing amount of analytics is performed on data that is procured in a real-time fashion to make real-time decisions. Such tasks include simple reporting on streams to sophisticated model building. However, the practicality of such analyses are impeded in several domains because they are faced with a fundamental trade-off between data collection latency and analysis accuracy. In this paper, we study this trade-off in the context of a specific domain, Cellular Radio Access Networks (RAN). Our choice of this domain is influenced by its commonalities with several other domains that produce real-time data, our access to a large live dataset, and their real-time nature and dimensionality which makes it a natural fit for a popular analysis technique, machine learning (ML). We find that the latency accuracy trade-off can be resolved using two broad, general techniques: intelligent data grouping and task formulations that leverage domain characteristics. Based on this, we present CellScope, a system that addresses this challenge by applying a domain specific formulation and application of Multi-task Learning (MTL) to RAN performance analysis. It achieves this goal using three techniques: feature engineering to transform raw data into effective features, a PCA inspired similarity metric to group data from geographically nearby base stations sharing performance commonalities, and a hybrid online-offline model for efficient model updates. Our evaluation of CellScope shows that its accuracy improvements over direct application of ML range from 2.5x to 4.4x while reducing the model update overhead by up to 4.8x. We have also used CellScope to analyze a live LTE consisting of over 2 million subscribers for a period of over 10 months, where it uncovered several problems and insights, some of them previously unknown.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@techreport{cellscope:tr16,
    Title                    = {Fast and Accurate Performance Analysis of {LTE} Radio Access Networks},
    Author                   = {A. P. Iyer and I. Stoica and M. Chowdhury and L. E. Li},
    Institution              = {CoRR},
    Year                     = {2016},
    Month                    = {May},
    Number                   = {abs/1605.04652},
    Abstract                 = {An increasing amount of analytics is performed on data that is procured in a real-time fashion to make real-time decisions. Such tasks include simple reporting on streams to sophisticated model building. However, the practicality of such analyses are impeded in several domains because they are faced with a fundamental trade-off between data collection latency and analysis accuracy.

In this paper, we study this trade-off in the context of a specific domain, Cellular Radio Access Networks (RAN). Our choice of this domain is influenced by its commonalities with several other domains that produce real-time data, our access to a large live dataset, and their real-time nature and dimensionality which makes it a natural fit for a popular analysis technique, machine learning (ML). We find that the latency accuracy trade-off can be resolved using two broad, general techniques: intelligent data grouping and task formulations that leverage domain characteristics. Based on this, we present CellScope, a system that addresses this challenge by applying a domain specific formulation and application of Multi-task Learning (MTL) to RAN performance analysis. It achieves this goal using three techniques: feature engineering to transform raw data into effective features, a PCA inspired similarity metric to group data from geographically nearby base stations sharing performance commonalities, and a hybrid online-offline model for efficient model updates. Our evaluation of CellScope shows that its accuracy improvements over direct application of ML range from 2.5x to 4.4x while reducing the model update overhead by up to 4.8x. We have also used CellScope to analyze a live LTE consisting of over 2 million subscribers for a period of over 10 months, where it uncovered several problems and insights, some of them previously unknown.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
                <li data-pub-venue=""
                    data-pub-cat="">
                    <div class="pub-block">
                        <div class="pub-title">
                            HUG: Multi-resource fairness for correlated and elastic demands
                            
                        </div>
                        
                        <div class="pub-authors">
                            <span class="pub-author pub-author-M.-Chowdhury ">M.&nbspChowdhury</span>, 
                            <span class="pub-author pub-author-Z.-Liu ">Z.&nbspLiu</span>, 
                            <span class="pub-author pub-author-A.-Ghodsi ">A.&nbspGhodsi</span>, and 
                            <span class="pub-author pub-author-I.-Stoica ">I.&nbspStoica</span>
                        </div>
                        
                        <div class="pub-abstract-frame">
                            <div class="pub-abstract">
                                <blockquote>In this paper, we study how to optimally provide isolation guarantees in multi-resource environments, such as public clouds, where a tenant's demands on different resources (links) are correlated. Unlike prior work such as Dominant Resource Fairness (DRF) that assumes static and fixed demands, we consider elastic demands. Our approach generalizes canonical max-min fairness to the multi-resource setting with correlated demands, and extends DRF to elastic demands. We consider two natural optimization objectives: isolation guarantee from a tenant's viewpoint and system utilization (work conservation) from an operator's perspective. We prove that in non-cooperative environments like public cloud networks, there is a strong tradeoff between optimal isolation guarantee and work conservation when demands are elastic. Even worse, work conservation can even decrease network utilization instead of improving it when demands are inelastic. We identify the root cause behind the tradeoff and present a provably optimal allocation algorithm, High Utilization with Guarantees (HUG), to achieve maximum attainable network utilization without sacrificing the optimal isolation guarantee, strategy-proofness, and other useful properties of DRF. In cooperative environments like private datacenter networks, HUG achieves both the optimal isolation guarantee and work conservation. Analyses, simulations, and experiments show that HUG provides better isolation guarantees, higher system utilization, and better tenant-level performance than its counterparts.
                                </blockquote>
                            </div>
                        </div>
                        <div class="pub-links">
                            <a class="pub-link-bibtex" data-clipboard-text="@inproceedings{hug:nsdi16,
    Title                    = {{HUG}: Multi-Resource Fairness for Correlated and Elastic Demands},
    Author                   = {M. Chowdhury and Z. Liu and A. Ghodsi and I. Stoica},
    Booktitle                = {USENIX NSDI},
    Year                     = {2016},
    Month                    = {March},
    Abstract                 = {In this paper, we study how to optimally provide isolation guarantees in multi-resource environments, such as public clouds, where a tenant's demands on different resources (links) are correlated. Unlike prior work such as Dominant Resource Fairness (DRF) that assumes static and fixed demands, we consider elastic demands. Our approach generalizes canonical max-min fairness to the multi-resource setting with correlated demands, and extends DRF to elastic demands. We consider two natural optimization objectives: isolation guarantee from a tenant's viewpoint and system utilization (work conservation) from an operator's perspective. We prove that in non-cooperative environments like public cloud networks, there is a strong tradeoff between optimal isolation guarantee and work conservation when demands are elastic. Even worse, work conservation can even decrease network utilization instead of improving it when demands are inelastic. We identify the root cause behind the tradeoff and present a provably optimal allocation algorithm, High Utilization with Guarantees (HUG), to achieve maximum attainable network utilization without sacrificing the optimal isolation guarantee, strategy-proofness, and other useful properties of DRF. In cooperative environments like private datacenter networks, HUG achieves both the optimal isolation guarantee and work conservation. Analyses, simulations, and experiments show that HUG provides better isolation guarantees, higher system utilization, and better tenant-level performance than its counterparts.}
}
">[bibtex]</a>
                            <a class="pub-link-abstract">[abstract]</a>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
    </div> <!-- pub-list -->
</div> <!-- publist -->


      </div>
      
      
      
    </div>
    

    
    
    


        </div>
        

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SymbioticLab</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>


  















  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  

<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="/assets/publist/publist.js"></script>


</body>
</html>
